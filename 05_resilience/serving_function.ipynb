{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Serving Function\n",
    "\n",
    "This notebook demonstrates the Serving Function design pattern using Keras\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple text classification model\n",
    "\n",
    "This model uses transfer learning with TensorFlow Hub and Keras. It is based on https://www.tensorflow.org/tutorials/keras/text_classification_with_hub\n",
    "\n",
    "It classifies movie reviews as positive or negative using the text of the review. The reviews come from an IMDB dataset that contains the text of 50,000 movie reviews from the Internet Movie Database. These are split into 25,000 reviews for training and 25,000 reviews for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Already installed if you are using Cloud AI Platform Notebooks\n",
    "#!pip install -q tensorflow-hub\n",
    "#!pip install -q tfds-nightly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_datasets as tfds\n",
    "train_data, test_data = tfds.load(\n",
    "    name=\"imdb_reviews\", \n",
    "    split=('train', 'test'),\n",
    "    as_supervised=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = 3 # 1/4 records is validation\n",
    "dataset_train = train_data.window(split, split + 1).flat_map(lambda *ds: ds[0] if len(ds) == 1 else tf.data.Dataset.zip(ds))\n",
    "dataset_validation = train_data.skip(split).window(1, split + 1).flat_map(lambda *ds: ds[0] if len(ds) == 1 else tf.data.Dataset.zip(ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = \"https://tfhub.dev/google/tf2-preview/gnews-swivel-20dim-with-oov/1\"\n",
    "hub_layer = hub.KerasLayer(embedding, input_shape=[], \n",
    "                           dtype=tf.string, trainable=True, name='full_text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "full_text (KerasLayer)       (None, 20)                389380    \n",
      "_________________________________________________________________\n",
      "h1_dense (Dense)             (None, 16)                336       \n",
      "_________________________________________________________________\n",
      "positive_review_logits (Dens (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 389,733\n",
      "Trainable params: 389,733\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(hub_layer)\n",
    "model.add(tf.keras.layers.Dense(16, activation='relu', name='h1_dense'))\n",
    "model.add(tf.keras.layers.Dense(1, name='positive_review_logits'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "37/37 [==============================] - 12s 333ms/step - loss: 0.7282 - accuracy: 0.6085 - val_loss: 0.6422 - val_accuracy: 0.6398\n",
      "Epoch 2/10\n",
      "37/37 [==============================] - 11s 292ms/step - loss: 0.6184 - accuracy: 0.6599 - val_loss: 0.5946 - val_accuracy: 0.6651\n",
      "Epoch 3/10\n",
      "37/37 [==============================] - 11s 298ms/step - loss: 0.5738 - accuracy: 0.6869 - val_loss: 0.5533 - val_accuracy: 0.7013\n",
      "Epoch 4/10\n",
      "37/37 [==============================] - 11s 296ms/step - loss: 0.5307 - accuracy: 0.7202 - val_loss: 0.5143 - val_accuracy: 0.7320\n",
      "Epoch 5/10\n",
      "37/37 [==============================] - 11s 295ms/step - loss: 0.4898 - accuracy: 0.7511 - val_loss: 0.4803 - val_accuracy: 0.7664\n",
      "Epoch 6/10\n",
      "37/37 [==============================] - 11s 299ms/step - loss: 0.4480 - accuracy: 0.7796 - val_loss: 0.4454 - val_accuracy: 0.7800\n",
      "Epoch 7/10\n",
      "37/37 [==============================] - 11s 295ms/step - loss: 0.4092 - accuracy: 0.8059 - val_loss: 0.4162 - val_accuracy: 0.8042\n",
      "Epoch 8/10\n",
      "37/37 [==============================] - 11s 297ms/step - loss: 0.3726 - accuracy: 0.8299 - val_loss: 0.3913 - val_accuracy: 0.8194\n",
      "Epoch 9/10\n",
      "37/37 [==============================] - 11s 294ms/step - loss: 0.3413 - accuracy: 0.8467 - val_loss: 0.3706 - val_accuracy: 0.8301\n",
      "Epoch 10/10\n",
      "37/37 [==============================] - 11s 296ms/step - loss: 0.3118 - accuracy: 0.8646 - val_loss: 0.3530 - val_accuracy: 0.8395\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "history = model.fit(dataset_train.shuffle(10000).batch(512),\n",
    "                    epochs=10,\n",
    "                    validation_data=dataset_validation.batch(512),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.359\n",
      "accuracy: 0.834\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(test_data.batch(512), verbose=2)\n",
    "\n",
    "for name, value in zip(model.metrics_names, results):\n",
    "  print(\"%s: %.3f\" % (name, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export the model for serving\n",
    "\n",
    "model.save() writes out a \"serve\" tag_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: export/default/sentiment_20200505_184058/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: export/default/sentiment_20200505_184058/assets\n"
     ]
    }
   ],
   "source": [
    "import os, datetime, shutil\n",
    "shutil.rmtree('export/default', ignore_errors=True)\n",
    "export_path = os.path.join('export', 'default', 'sentiment_{}'.format(datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")))\n",
    "model.save(export_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "export/default\n",
      "export/default/sentiment_20200505_184058\n",
      "export/default/sentiment_20200505_184058/variables\n",
      "export/default/sentiment_20200505_184058/variables/variables.data-00000-of-00001\n",
      "export/default/sentiment_20200505_184058/variables/variables.index\n",
      "export/default/sentiment_20200505_184058/assets\n",
      "export/default/sentiment_20200505_184058/assets/tokens.txt\n",
      "export/default/sentiment_20200505_184058/saved_model.pb\n"
     ]
    }
   ],
   "source": [
    "!find export/default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The given SavedModel SignatureDef contains the following input(s):\n",
      "  inputs['full_text_input'] tensor_info:\n",
      "      dtype: DT_STRING\n",
      "      shape: (-1)\n",
      "      name: serving_default_full_text_input:0\n",
      "The given SavedModel SignatureDef contains the following output(s):\n",
      "  outputs['positive_review_logits'] tensor_info:\n",
      "      dtype: DT_FLOAT\n",
      "      shape: (-1, 1)\n",
      "      name: StatefulPartitionedCall_2:0\n",
      "Method name is: tensorflow/serving/predict\n"
     ]
    }
   ],
   "source": [
    "!saved_model_cli show --dir {export_path} --tag_set serve --signature_def serving_default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.46924272]\n",
      " [0.85492635]\n",
      " [0.15715358]]\n"
     ]
    }
   ],
   "source": [
    "## illustrates how we can load this model and do inference based on the signature above\n",
    "restored = tf.keras.models.load_model(export_path)\n",
    "review1 = 'The film is based on a prize-winning novel.' # neutral\n",
    "review2 = 'The film is fast moving and has several great action scenes.' # positive\n",
    "review3 = 'The film was very boring. I walked out half-way.' # negative\n",
    "\n",
    "infer = restored.signatures['serving_default']\n",
    "outputs = infer(full_text_input=tf.constant([review1, review2, review3])) # note input name\n",
    "logit = outputs['positive_review_logits']  # note output name\n",
    "print(1 / (1 + np.exp(-logit))) # probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom serving function\n",
    "\n",
    "Let's write out a new signature. But this time, let's carry out the sigmoid operation, so that the model outputs a probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: export/probs/sentiment_20200505_192836/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: export/probs/sentiment_20200505_192836/assets\n"
     ]
    }
   ],
   "source": [
    "@tf.function(input_signature=[tf.TensorSpec([None], dtype=tf.string)])\n",
    "def add_prob(reviews):\n",
    "    logits = model(reviews, training=False) # the model is captured via closure\n",
    "    probs = tf.sigmoid(logits)\n",
    "    return {\n",
    "        'positive_review_logits' : logits,\n",
    "        'positive_review_probability' : probs\n",
    "    }\n",
    "shutil.rmtree('export/probs', ignore_errors=True)\n",
    "probs_export_path = os.path.join('export', 'probs', 'sentiment_{}'.format(datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")))\n",
    "model.save(probs_export_path, signatures={'serving_default': add_prob})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The given SavedModel SignatureDef contains the following input(s):\n",
      "  inputs['reviews'] tensor_info:\n",
      "      dtype: DT_STRING\n",
      "      shape: (-1)\n",
      "      name: serving_default_reviews:0\n",
      "The given SavedModel SignatureDef contains the following output(s):\n",
      "  outputs['positive_review_logits'] tensor_info:\n",
      "      dtype: DT_FLOAT\n",
      "      shape: (-1, 1)\n",
      "      name: StatefulPartitionedCall_2:0\n",
      "  outputs['positive_review_probability'] tensor_info:\n",
      "      dtype: DT_FLOAT\n",
      "      shape: (-1, 1)\n",
      "      name: StatefulPartitionedCall_2:1\n",
      "Method name is: tensorflow/serving/predict\n"
     ]
    }
   ],
   "source": [
    "!saved_model_cli show --dir {probs_export_path} --tag_set serve --signature_def serving_default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.46924272]\n",
      " [0.85492635]\n",
      " [0.15715358]], shape=(3, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "restored = tf.keras.models.load_model(probs_export_path)\n",
    "infer = restored.signatures['serving_default']\n",
    "outputs = infer(reviews=tf.constant([review1, review2, review3])) # note input name\n",
    "probs = outputs['positive_review_probability']  # note output name\n",
    "print(probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy to Cloud AI Platform Predictions\n",
    "\n",
    "We can deploy the model to AI Platform Predictions which will take care of scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "export/probs/sentiment_20200505_192836\n"
     ]
    }
   ],
   "source": [
    "!find export/probs | head -2 | tail -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imdb\n",
      "Model imdb already exists\n",
      "\n",
      "Creating version v1 from export/probs/sentiment_20200505_192836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Listed 0 items.\n",
      "Creating version (this might take a few minutes)......\n",
      "........................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................done.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "MODEL_LOCATION=$(find export/probs | head -2 | tail -1)\n",
    "MODEL_NAME=imdb\n",
    "MODEL_VERSION=v1\n",
    "\n",
    "TFVERSION=2.1\n",
    "REGION=us-central1\n",
    "BUCKET=ai-analytics-solutions-kfpdemo\n",
    "\n",
    "# create the model if it doesn't already exist\n",
    "modelname=$(gcloud ai-platform models list | grep -w \"$MODEL_NAME\")\n",
    "echo $modelname\n",
    "if [ -z \"$modelname\" ]; then\n",
    "   echo \"Creating model $MODEL_NAME\"\n",
    "   gcloud ai-platform models create ${MODEL_NAME} --regions $REGION\n",
    "else\n",
    "   echo \"Model $MODEL_NAME already exists\"\n",
    "fi\n",
    "\n",
    "# delete the model version if it already exists\n",
    "modelver=$(gcloud ai-platform versions list --model \"$MODEL_NAME\" | grep -w \"$MODEL_VERSION\")\n",
    "echo $modelver\n",
    "if [ \"$modelver\" ]; then\n",
    "   echo \"Deleting version $MODEL_VERSION\"\n",
    "   yes | gcloud ai-platform versions delete ${MODEL_VERSION} --model ${MODEL_NAME}\n",
    "   sleep 10\n",
    "fi\n",
    "\n",
    "\n",
    "echo \"Creating version $MODEL_VERSION from $MODEL_LOCATION\"\n",
    "gcloud ai-platform versions create ${MODEL_VERSION} \\\n",
    "       --model ${MODEL_NAME} --origin ${MODEL_LOCATION} --staging-bucket gs://${BUCKET} \\\n",
    "       --runtime-version $TFVERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing input.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile input.json\n",
    "{\"reviews\": \"The film is based on a prize-winning novel.\"}\n",
    "{\"reviews\": \"The film is fast moving and has several great action scenes.\"}\n",
    "{\"reviews\": \"The film was very boring. I walked out half-way.\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POSITIVE_REVIEW_LOGITS  POSITIVE_REVIEW_PROBABILITY\n",
      "[-0.12318471074104309]  [0.469242662191391]\n",
      "[1.773773431777954]     [0.854926347732544]\n",
      "[-1.6795613765716553]   [0.15715356171131134]\n",
      "\n",
      "\n",
      "To take a quick anonymous survey, run:\n",
      "  $ gcloud survey\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!gcloud ai-platform predict --model imdb --json-instances input.json --version v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response = {'predictions': [{'positive_review_probability': [0.469242662191391], 'positive_review_logits': [-0.12318471074104309]}, {'positive_review_probability': [0.854926347732544], 'positive_review_logits': [1.773773431777954]}, {'positive_review_probability': [0.15715356171131134], 'positive_review_logits': [-1.6795613765716553]}]}\n"
     ]
    }
   ],
   "source": [
    "from googleapiclient import discovery\n",
    "from oauth2client.client import GoogleCredentials\n",
    "import json\n",
    "\n",
    "credentials = GoogleCredentials.get_application_default()\n",
    "api = discovery.build(\"ml\", \"v1\", credentials = credentials,\n",
    "            discoveryServiceUrl = \"https://storage.googleapis.com/cloud-ml/discovery/ml_v1_discovery.json\")\n",
    "\n",
    "request_data = {\"instances\":\n",
    "  [\n",
    "      {\"reviews\": \"The film is based on a prize-winning novel.\"},\n",
    "      {\"reviews\": \"The film is fast moving and has several great action scenes.\"},\n",
    "      {\"reviews\": \"The film was very boring. I walked out half-way.\"}\n",
    "  ]\n",
    "}\n",
    "\n",
    "parent = \"projects/{}/models/imdb\".format(\"ai-analytics-solutions\", \"v1\") # use default version\n",
    "\n",
    "response = api.projects().predict(body = request_data, name = parent).execute()\n",
    "print(\"response = {0}\".format(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.469242662191391\n"
     ]
    }
   ],
   "source": [
    "print(response['predictions'][0]['positive_review_probability'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright 2020 Google Inc. Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
